\subsection*{Introduction}

A simple multi-\/thread key-\/value database by Lemonion. Inc.

See more information in our official documentation \href{https://tc-imba.github.io/VE482-p2/}{\tt H\+T\+ML}/\href{../latex/refman.pdf}{\tt P\+DF}

\subsection*{Compilation}

\subsubsection*{Debug}

This version is used for debugging. 
\begin{DoxyCode}
mkdir debug && cd debug
cmake ..  -DCMAKE\_BUILD\_TYPE=Debug
make lemondb
src/lemondb
\end{DoxyCode}


\subsubsection*{Release}

This version is used for performance test. 
\begin{DoxyCode}
mkdir release && cd release
cmake ..  -DCMAKE\_BUILD\_TYPE=Release
make lemondb
src/lemondb
\end{DoxyCode}


\subsection*{Testing}

For a small test case, just use the files under {\ttfamily test} folder. Set the working directory as {\ttfamily test}, set the program argument as {\ttfamily test.\+query} or {\ttfamily test$\ast$.in}.

The test cases are too bug, so they are stored with Git L\+FS. See more information on \href{https://git-lfs.github.com/}{\tt Git L\+FS pages}.

Once Git L\+FS extension is installed, you can download the test cases through cloning the submodule\+: 
\begin{DoxyCode}
git submodule init
git submodule update
\end{DoxyCode}


Set the working directory as {\ttfamily testcase/sample}, set the program argument as {\ttfamily $\ast$.query}, simply start debugging! (The loading query in all test files should be based on {\ttfamily testcase/sample} directory)

\subsection*{Documentation}

The working flow of Lemon\+DB is written by ourselves.

The class / function documentation is generated by \href{http://www.doxygen.nl/}{\tt Doxygen}.

\subsubsection*{Design}


\begin{DoxyItemize}
\item We design this program to make it can create 8 threads. We classify the queries using table and add them into queryqueue of corresponding table when we read them from the file. Once the table needed has been loaded completely, we will execute the queries as the order in queue and read query if the file hasn\textquotesingle{}t ended at the same time.
\item Queries in the queryqueue will be run in the parallel.
\item Even in one query, for data queries that need searching and calculation such as S\+UB or S\+UM in a large table, we use a function add\+Iteration\+Task to divide the table into several parts and search or calculate these parts simultaneously. Because the efficiency depends on the ratio between size of every part and size of the table, we did experiments and then find 10000 is a good size. For queries like T\+R\+U\+N\+C\+A\+TE and I\+N\+S\+E\+RT, since they don\textquotesingle{}t have to traverse the whole table, we don\textquotesingle{}t add task for them.
\item The query class will use a \char`\"{}combine\char`\"{} function to check whether all the tasks dispatched by one query are all finished and organize them in the order and show on the screen.
\item When the user ask for quit, the quit query will check whether all tasks have already finished and and exit the program.
\end{DoxyItemize}

\subsubsection*{Performance Improvement}

We use many tricks to improve performance\+:
\begin{DoxyItemize}
\item Since we use a vector to store all data in a table, we obtain the advantage of efficient random access. Meanwhile, deleting and inserting datum becomes less efficient inevitably. However, we use some tricks to handle this issue. Notice that the vector is unordered, so for I\+N\+S\+E\+RT query it can be trivially appended to the vector with O(1). Then for D\+E\+L\+E\+TE and D\+U\+P\+L\+I\+C\+A\+TE query, we use a temporary vector {\ttfamily data\+New}. When iterating through data, those won\textquotesingle{}t be deleted will be moved to data\+New by {\ttfamily std\+::move}, which is extremely fast. Then we simply swap {\ttfamily data} and {\ttfamily data\+New}, clear {\ttfamily data\+New} for further use. For D\+U\+P\+L\+I\+C\+A\+TE, things are slightly different. We insert duplicated data into {\ttfamily data\+New}, and then we append {\ttfamily data\+New} to {\ttfamily data}. These iteration can be executed in parallel, so {\ttfamily data\+New} is, of course, protected by a mutex.
\item Another great improvement is for those query with a condition \textquotesingle{}K\+EY = some\+Key\textquotesingle{}. Making use of efficient random access, we keep a {\ttfamily key\+Map} which stores index for given key. With this map, we can complete those query very efficiently, without iterating through data.
\item For those query without given key, we also improve the speed of evaluating condition. This is done by computing the condition explicitly for a specific query (by {\ttfamily std\+::function}), and simply pass this function to it. By doing so, we don\textquotesingle{}t need to repeatedly compare string, convert string to integer, even switch among operators. This can save huge amount of time, because originally every datum use one general evaluating function. Now we just need to compute it once per query.
\item In some trivial cases atomic\+\_\+int is used instead of having a mutex because it is much faster.
\end{DoxyItemize}

\subsubsection*{Problems Solved}

Due to our sophisticated design, we ran into many problems. These are some of them\+:
\begin{DoxyItemize}
\item We have encountered many problems about the query queue. The problem of L\+O\+AD query is the most difficult one, because it doesn\textquotesingle{}t specify a table name. In our design, every table has a query queue so that we can decide the order to execute them, following reader/writer pattern. But L\+O\+AD doesn\textquotesingle{}t have it, so it\textquotesingle{}s very difficult to deicide where to put it, because the file may even not exist when the query is parsed and put into some queue. D\+U\+MP query is the reason we concern about this issue, so we solve it by keeping a map from filename to tablename. With this map, L\+O\+AD can decide whether the file is (or will be) created by D\+U\+MP or should exist already.
\item Another issue is C\+O\+P\+Y\+T\+A\+B\+LE. This is the other query which can create a table, in which case it is responsible for starting the query queue to execute. And the problem is that C\+O\+P\+Y\+T\+A\+B\+LE involves 2 table, so it should be pushed to both tables. And only when both query queues come to this query should it execute. This is done by keeping each other\textquotesingle{}s pointer in it.
\item Other problems such as mutex or deadlock are less encountered, because we consider carefully about implementation before we start to code. 
\end{DoxyItemize}